{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data curation notebook: Result visualization and re-training config generation \n",
    "\n",
    "### Notebook Overview\n",
    "At a high-level, this notebook contains code for (1) loading and visualizing various types of data curation results (e.g., curated dataset quality) and (2) generating configuration files from these results, so that new policies can be trained on datasets curated by different methods. This code is only relevant *after* (base) policies have been trained and data curation methods have been applied to score individual demonstrations within datasets. I.e., this notebook will show you how to load those demonstration scores (along with other data) from disk, perform some basic operations on them (e.g., combine scores from different methods), and generate simple plots visualizing curation metrics of interest. \n",
    "\n",
    "The notebook is organized into four sections:\n",
    "1. **Sec. 1:** Contains all utility functions for loading, computing, and plotting results, along with other handy utilities. \n",
    "2. **Sec. 2:** Provides code samples for visualizing curated dataset quality for two curation tasks defined in the paper (filtering training demos and selecting holdout demos).\n",
    "3. **Sec. 3:** Provides code samples for generating curation configuration files for re-training policies with curated datasets (for both the filtering and selection tasks). \n",
    "4. **Sec. 4:** Provides code samples for visualizing the performance of policies trained with curated datasets (for both the filtering and selection tasks).\n",
    "\n",
    "We encourage users to modify the code as necessary to suit your needs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: If cell below throws an error, try running this cell multiple times first.\n",
    "\n",
    "from typing import Optional, List, Tuple, Dict, Any, Union, Callable\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "serif = True\n",
    "if serif:\n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "else:\n",
    "    plt.rcParams[\"font.family\"] = \"Liberation Sans\"\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"ps.fonttype\"] = 42\n",
    "import seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.lines as mlines\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import yaml\n",
    "import hydra\n",
    "import pickle\n",
    "import pathlib\n",
    "import omegaconf\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "current_dir = pathlib.Path.cwd()\n",
    "if \"notebooks\" in str(current_dir):\n",
    "    os.chdir(current_dir.parent)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from diffusion_policy.dataset.episode_dataset import BatchEpisodeDataset\n",
    "from diffusion_policy.dataset.pusht_dataset import PushTLowdimDataset\n",
    "from diffusion_policy.dataset.pusht_image_dataset import PushTImageDataset\n",
    "from diffusion_policy.dataset.robomimic_replay_lowdim_dataset import RobomimicReplayLowdimDataset\n",
    "from diffusion_policy.dataset.robomimic_replay_image_dataset import RobomimicReplayImageDataset\n",
    "from diffusion_policy.dataset.real_franka_image_dataset import RealFrankaImageDataset\n",
    "from diffusion_policy.policy.diffusion_unet_lowdim_policy import DiffusionUnetLowdimPolicy\n",
    "\n",
    "# Utility functions.\n",
    "from diffusion_policy.common.trak_util import (\n",
    "    DemoDatasetType,\n",
    "    get_dataset_metadata,\n",
    "    get_best_checkpoint,\n",
    "    get_index_checkpoint,\n",
    "    get_policy_from_checkpoint,\n",
    ")\n",
    "from diffusion_policy.common.results_util import (\n",
    "    DEMO_RESULT_KEYS,\n",
    "    ROLLOUT_RESULT_KEYS,\n",
    "    CURATION_KEY_NAME_FN,\n",
    "    get_offline_state_diversity_exp_key,\n",
    "    get_online_state_similarity_exp_key,\n",
    "    get_online_trak_influence_exp_key,\n",
    "    get_last_n_log_keys,\n",
    ")\n",
    "\n",
    "if \"notebooks\" in str(current_dir):\n",
    "    os.chdir(current_dir.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: If this cell throws an error, try running the cell above multiple times first.\n",
    "\n",
    "# Set up directories.\n",
    "device = torch.device(\"cpu\")\n",
    "output_dir = current_dir / \"data\" / \"outputs\"\n",
    "config_dir = current_dir / \"configs\"\n",
    "train_dir = output_dir / \"train\"\n",
    "eval_dir = output_dir / \"eval_save_episodes\"\n",
    "real_train_dir = output_dir / \"train_real\"\n",
    "real_eval_dir = output_dir / \"eval_save_episodes_real\"\n",
    "result_dir = current_dir / \"notebooks\" / \"outputs\" / \"official\"\n",
    "\n",
    "# Curation configuration directory.\n",
    "SAVE_CURATION_CONFIGS = True\n",
    "curation_config_dir = config_dir / \"curation\"\n",
    "if not curation_config_dir.exists():\n",
    "    curation_config_dir.mkdir()\n",
    "    (curation_config_dir / \"low_dim\").mkdir()\n",
    "    (curation_config_dir / \"image\").mkdir()\n",
    "\n",
    "# Debug mode.\n",
    "DEBUG = False\n",
    "dbprint = print if DEBUG else lambda x: ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 1: Run utilities for use in subsequent cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 1.1: Loading utilities\n",
    "**Description:** Code related to loading demonstration scores from disk, along with other necessary data (e.g., datasets, checkpoints, ground-truth demonstration labels) for visualization and data curation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path: Union[str, pathlib.Path]) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Load pickle data.\"\"\"\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        data = None\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_online_trak_influence_quality_exp_key(\n",
    "    metric: str = \"net\",\n",
    "    num_rollouts: str = \"all\",\n",
    "    method_prefix: bool = True,\n",
    "    aggr_fn: str = \"sum_of_sum\"\n",
    ") -> List[str]:\n",
    "    \"\"\"Get influence quality (CUPID-Quality) experiment keys.\"\"\"\n",
    "    inf_key = get_online_trak_influence_exp_key(\n",
    "        aggr_fn=aggr_fn,\n",
    "        metric=metric,\n",
    "        num_rollouts=num_rollouts,\n",
    "        method_prefix=method_prefix,\n",
    "    )\n",
    "    minimax_key = get_online_trak_influence_exp_key(\n",
    "        aggr_fn=\"min_of_max\",\n",
    "        metric=metric,\n",
    "        num_rollouts=num_rollouts,\n",
    "        method_prefix=method_prefix,\n",
    "    )\n",
    "    maximin_key = get_online_trak_influence_exp_key(\n",
    "        aggr_fn=\"max_of_min\",\n",
    "        metric=metric,\n",
    "        num_rollouts=num_rollouts,\n",
    "        method_prefix=method_prefix,\n",
    "    )\n",
    "    \n",
    "    return [inf_key, minimax_key, maximin_key]\n",
    "\n",
    "\n",
    "def get_load_result_kwargs(\n",
    "    task: str, \n",
    "    policy: str,\n",
    "    seed: int,\n",
    "    train_date: str = \"25.03.03\",\n",
    "    eval_date: str = \"25.03.03\",\n",
    "    result_date: str = \"25.03.03\",\n",
    "    train_ckpt: str = \"latest\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Return kwarg dictionaries for result loading functions.\"\"\"\n",
    "    return {\n",
    "        \"train_exp_kwargs\": {\n",
    "            \"task\": task,\n",
    "            \"policy\": policy,\n",
    "            \"train_date\": train_date,\n",
    "            \"exp_date\": train_date,\n",
    "            \"train_ckpt\": train_ckpt,\n",
    "            \"train_seed\": seed,\n",
    "        },\n",
    "        \"eval_exp_kwargs\": {\n",
    "            \"task\": task,\n",
    "            \"policy\": policy,\n",
    "            \"eval_date\": eval_date,\n",
    "            \"train_date\": train_date,\n",
    "            \"train_seed\": seed,\n",
    "            \"train_ckpt\": train_ckpt,\n",
    "        },\n",
    "        \"result_exp_kwargs\": {\n",
    "            \"result_date\": result_date,\n",
    "            \"result_seed\": 0\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def get_eval_exp_path(\n",
    "    task: str = \"pusht\",\n",
    "    policy: str = \"diffusion_unet_lowdim\",\n",
    "    eval_date: str = \"25.03.03\",\n",
    "    train_date: str = \"25.03.03\",\n",
    "    train_seed: int = 0,\n",
    "    train_ckpt: str = \"latest\",\n",
    "    real_exp: bool = False,\n",
    "    **kwargs,\n",
    ") -> pathlib.Path:\n",
    "    \"\"\"Return path to evaluation experiment directory.\"\"\"\n",
    "    root_dir = real_eval_dir if real_exp else eval_dir\n",
    "    train_exp_name = f\"{train_date}_train_{policy}_{task}_{train_seed}\"\n",
    "    return root_dir / eval_date / train_exp_name / train_ckpt\n",
    "\n",
    "\n",
    "def get_train_exp_path(\n",
    "    task: str = \"pusht\",\n",
    "    policy: str = \"diffusion_unet_lowdim\",\n",
    "    train_date: str = \"25.03.03\",\n",
    "    exp_date: str = \"25.03.03\",\n",
    "    train_seed: int = 0,\n",
    "    real_exp: bool = False,\n",
    "    curate_dataset: bool = False,\n",
    "    curation_method: Optional[str] = None,\n",
    "    filter_ratio: Optional[float] = None,\n",
    "    select_ratio: Optional[float] = None,\n",
    "    **kwargs,\n",
    ") -> pathlib.Path:\n",
    "    \"\"\"Return path to training experiment directory.\"\"\"\n",
    "    root_dir = real_train_dir if real_exp else train_dir\n",
    "    train_exp_name = f\"{exp_date}_train_{policy}_{task}_{train_seed}\"\n",
    "    if curate_dataset:\n",
    "        assert (\n",
    "            (curation_method is not None) and\n",
    "            (filter_ratio is not None and 0.0 <= filter_ratio <= 1.0) and\n",
    "            (select_ratio is not None and 0.0 <= select_ratio <= 1.0)\n",
    "        ), \"Curation arguments must be set together\"\n",
    "        train_exp_name = f\"{train_exp_name}-curation_{curation_method}-filter_{filter_ratio:.2f}-select_{select_ratio:.2f}\"\n",
    "    return root_dir / train_date / train_exp_name\n",
    "\n",
    "\n",
    "def get_train_checkpoint_paths(\n",
    "    task: str = \"pusht\",\n",
    "    policy: str = \"diffusion_unet_lowdim\",\n",
    "    train_date: str = \"25.03.03\",\n",
    "    exp_date: str = \"25.03.03\",\n",
    "    real_exp: bool = False,\n",
    "    filter_latest: bool = False,\n",
    "    train_seed: Optional[int] = None,\n",
    ") -> List[pathlib.Path]:\n",
    "    \"\"\"Return paths to training checkpoints.\"\"\"\n",
    "    # Get experiment directory.\n",
    "    root_dir = real_train_dir if real_exp else train_dir\n",
    "    \n",
    "    # If train seed is not provided, checkpoint paths for all existing training seeds are returned.\n",
    "    if train_seed is None:\n",
    "        exp_root_dir = root_dir / train_date\n",
    "        exp_name_prefix = f\"{exp_date}_train_{policy}_{task}\"\n",
    "        exp_dirs = sorted(\n",
    "            [x for x in exp_root_dir.iterdir() if exp_name_prefix in str(x)]\n",
    "        )\n",
    "\n",
    "    # If train seed is provided, checkpoint paths for the specified training seed are returned.\n",
    "    else:\n",
    "        exp_dirs = [\n",
    "            get_train_exp_path(\n",
    "                task=task,\n",
    "                policy=policy,\n",
    "                train_date=train_date,\n",
    "                exp_date=exp_date,\n",
    "                train_seed=train_seed,\n",
    "                real_exp=real_exp,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # Get checkpoint paths.\n",
    "    ckpt_paths: List[pathlib.Path] = []\n",
    "    for exp_dir in exp_dirs:\n",
    "        ckpt_dir = exp_dir / \"checkpoints\"\n",
    "        exp_ckpt_paths = sorted(list(ckpt_dir.iterdir()))\n",
    "        ckpt_paths.extend(exp_ckpt_paths)\n",
    "\n",
    "    if filter_latest:\n",
    "        ckpt_paths = [p for p in ckpt_paths if \"latest\" not in p.stem]\n",
    "\n",
    "    return ckpt_paths\n",
    "\n",
    "\n",
    "def get_policy_and_config(\n",
    "    train_ckpt: Union[str, int], \n",
    "    **kwargs\n",
    ") -> Union[nn.Module, Tuple[nn.Module, omegaconf.DictConfig]]:\n",
    "    \"\"\"Load policy and config from checkpoint.\"\"\"\n",
    "    checkpoint = None\n",
    "    checkpoints = get_train_checkpoint_paths(**kwargs)\n",
    "    if isinstance(train_ckpt, int):\n",
    "        checkpoint = get_index_checkpoint(checkpoints, int(train_ckpt))\n",
    "    elif isinstance(train_ckpt, str):\n",
    "        if train_ckpt == \"best\":\n",
    "            checkpoint = get_best_checkpoint(checkpoints)\n",
    "        else:\n",
    "            for ckpt_path in checkpoints:\n",
    "                checkpoint = ckpt_path if train_ckpt in ckpt_path.stem else None\n",
    "\n",
    "    if checkpoint is None:\n",
    "        raise ValueError(f\"Checkpoint type {train_ckpt} is not supported.\")\n",
    "    \n",
    "    print(f\"Loading checkpoint {checkpoint}\")\n",
    "    return get_policy_from_checkpoint(checkpoint, return_cfg=True, device=device)\n",
    "\n",
    "\n",
    "def get_demo_quality_labels(cfg: omegaconf.DictConfig, dataset: DemoDatasetType) -> Optional[np.ndarray]:\n",
    "    \"\"\"Return an array of ground-truth demonstration labels. The length of the array is equal to the number of \"training\" demonstrations in the dataset.\"\"\"\n",
    "    if cfg.task.dataset_type != \"mh\":\n",
    "        return None\n",
    "    \n",
    "    # Get demo indices and quality labels depending on dataset type.\n",
    "    if isinstance(dataset, (RobomimicReplayLowdimDataset, RobomimicReplayImageDataset)):\n",
    "        decode_fn = lambda x: np.array([int(name.decode().split(\"_\")[-1]) for name in x])\n",
    "        with h5py.File(dataset._dataset_path) as file:\n",
    "            if any(x in cfg.task_name for x in [\"lift\", \"can\", \"square\"]):\n",
    "                # Note: Lift, Can, Square have 3 quality tiers.\n",
    "                demo_quality_vals = [1.0, 2.0, 3.0]\n",
    "                demo_quality_sets = [\"worse\", \"okay\", \"better\"]\n",
    "                demo_quality_idxs = [decode_fn(file[\"mask\"][s][:]) for s in demo_quality_sets]\n",
    "            elif \"transport\" in cfg.task_name:\n",
    "                # ---------------------------------------------------------------------------------------------------------------------------\n",
    "                # Note: Transport has 6 demo subsets, with two demonstrators per subset. Therefore, there is not 'correct' way to define demo quality.\n",
    "                # That said, the chosen quality labels only affect visualization, not the actual performance of the policy after curated re-training. \n",
    "                # Thus, we use a custom definition of demo quality, which is a weighted average of the two demonstrators. We note that other \n",
    "                # definitions are equally valid, and we encourage the user to experiment with them to get a better understanding of the behavior\n",
    "                # of different curation methods, and how they rank-order demonstrations differently.\n",
    "                # ---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "                # demo_quality_vals = [1.0, 1.5, 2.0, 2.5, 3.0, 1.5] # Mean of demonstrator quality.\n",
    "                # demo_quality_vals = [1.0, 2.0, 2.0, 3.0, 3.0, 3.0] # Max of demonstrator quality.\n",
    "                # demo_quality_vals = [1.0, 1.0, 2.0, 2.0, 3.0, 1.0] # Min of demonstrator quality.\n",
    "                demo_quality_vals = [1.0, (1.0 * 1/3) + (2.0 * 2/3), 2.0, (2.0 * 1/3) + (3.0 * 2/3), 3.0, (1.0 * 1/3) + (3.0 * 2/3)] # Custom of demonstrator quality.\n",
    "                demo_quality_sets = [\"worse\", \"worse_okay\", \"okay\", \"okay_better\", \"better\", \"worse_better\"]\n",
    "                demo_quality_idxs = [decode_fn(file[\"mask\"][s][:]) for s in demo_quality_sets]\n",
    "            else:\n",
    "                raise ValueError(f\"Task {cfg.task_name} is not supported.\")\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # Extract quality labels for training demonstrations.\n",
    "    quality_labels = np.zeros(len(dataset.train_mask), dtype=float)\n",
    "    for demo_idxs, quality_val in zip(demo_quality_idxs, demo_quality_vals):\n",
    "        quality_labels[demo_idxs] = quality_val\n",
    "    quality_labels = quality_labels[dataset.train_mask]\n",
    "    \n",
    "    assert np.all(quality_labels > 0), \"All demos should have a quality label greater than zero.\"\n",
    "    return quality_labels\n",
    "\n",
    "\n",
    "def get_demonstration_scores_result_data(\n",
    "    eval_exp_path: pathlib.Path,\n",
    "    result_date: str = \"25.03.03\",\n",
    "    result_seed: int = 0,\n",
    ") -> Dict[str, Dict[str, np.ndarray]]:\n",
    "    \"\"\"Return scores computed over training and holdout demonstrations.\"\"\"\n",
    "    result_dir = eval_exp_path / f\"{result_date}_demonstration_scores-seed={result_seed}\"\n",
    "    \n",
    "    result_data = defaultdict(dict)\n",
    "    for key in DEMO_RESULT_KEYS:\n",
    "\n",
    "        data = load_pickle(result_dir / f\"{key}.pkl\")\n",
    "        if data is None:\n",
    "            continue\n",
    "\n",
    "        for split in [\"train\", \"holdout\"]:\n",
    "            if split in data:\n",
    "                split_result = data[split]\n",
    "                if isinstance(split_result, np.ndarray):\n",
    "                    result_data[split][key] = split_result\n",
    "                elif isinstance(split_result, dict):\n",
    "                    for subkey, value in split_result.items():\n",
    "                        if isinstance(value, np.ndarray):\n",
    "                            result_data[split][f\"{key}-{subkey}\"] = value\n",
    "        \n",
    "        dbprint(f\"Loaded {key} results.\")\n",
    "\n",
    "    return result_data\n",
    "\n",
    "\n",
    "def get_deminf_result_data(\n",
    "    task: str,\n",
    "    train_date: str,\n",
    "    train_seed: int,\n",
    "    policy: str,\n",
    "    **kwargs: Any,\n",
    ") -> Optional[Dict[str, np.ndarray]]:\n",
    "    \"\"\"Return DemInf scores computed over training and holdout demonstrations. \n",
    "    Note: DemInf scores are computed using their official implementation at https://github.com/jhejna/demonstration-information.\"\"\"\n",
    "    state = \"lowdim\" if \"lowdim\" in policy else \"image\"\n",
    "    result_file = output_dir / \"deminf\" / train_date / f\"{task}_{state}_seed{train_seed}.npz\"\n",
    "    try: \n",
    "        result_data = dict(np.load(str(result_file)))\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "    \n",
    "    dbprint(f\"Loaded offline_deminf results.\")\n",
    "    return result_data\n",
    "\n",
    "\n",
    "def get_rollout_scores_result_data(\n",
    "    eval_exp_path: pathlib.Path,\n",
    "    result_date: str = \"25.03.03\",\n",
    "    result_seed: int = 0,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Return scores computed over test rollouts.\"\"\"\n",
    "    result_dir = eval_exp_path / f\"{result_date}_rollout_scores-seed={result_seed}\"\n",
    "    \n",
    "    result_data = {}\n",
    "    for key in ROLLOUT_RESULT_KEYS:\n",
    "\n",
    "        data = load_pickle(result_dir / f\"{key}.pkl\")\n",
    "        if data is None:\n",
    "            continue\n",
    "        \n",
    "        assert isinstance(data[\"test\"], np.ndarray)\n",
    "        result_data[key] = data[\"test\"]\n",
    "        dbprint(f\"Loaded {key} results.\")\n",
    "\n",
    "    return result_data\n",
    "\n",
    "\n",
    "def load_result_data(\n",
    "    train_exp_kwargs: Dict[str, Any],\n",
    "    eval_exp_kwargs: Dict[str, Any],\n",
    "    result_exp_kwargs: Dict[str, Any],\n",
    "    return_policy: bool = False,\n",
    "    return_datasets: bool = False,\n",
    "    real_exp: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Load all necessary data for experiment analysis.\"\"\"\n",
    "    # Evaluation directory.\n",
    "    eval_exp_path = get_eval_exp_path(**eval_exp_kwargs, real_exp=real_exp)\n",
    "\n",
    "    # Load policy.\n",
    "    policy, cfg = get_policy_and_config(**train_exp_kwargs, real_exp=real_exp)\n",
    "\n",
    "    # Load training set and metadata.\n",
    "    train_set: DemoDatasetType = hydra.utils.instantiate(cfg.task.dataset)\n",
    "    train_set_metadata = get_dataset_metadata(cfg, train_set)\n",
    "    train_set_metadata[\"demo_mask\"] = train_set.train_mask\n",
    "    train_set_metadata[\"quality_labels\"] = get_demo_quality_labels(cfg, train_set)\n",
    "    train_idxs = np.where(train_set.train_mask)[0]\n",
    "\n",
    "    # Load holdout set and metadata.\n",
    "    holdout_set = train_set.get_holdout_dataset()\n",
    "    holdout_set_metadata = get_dataset_metadata(cfg, holdout_set)\n",
    "    holdout_set_metadata[\"demo_mask\"] = holdout_set.train_mask\n",
    "    holdout_set_metadata[\"quality_labels\"] = get_demo_quality_labels(cfg, holdout_set)\n",
    "\n",
    "    # Load test set and metadata.\n",
    "    try: \n",
    "        test_set = BatchEpisodeDataset(\n",
    "            batch_size=1,\n",
    "            dataset_path=eval_exp_path / \"episodes\",\n",
    "            exec_horizon=1,\n",
    "            sample_history=0,\n",
    "        )\n",
    "        test_set_metadata = get_dataset_metadata(cfg, test_set)\n",
    "    except FileNotFoundError:\n",
    "        test_set = None\n",
    "        test_set_metadata = None\n",
    "    \n",
    "    # Load demonstration score results.\n",
    "    result_data = get_demonstration_scores_result_data(eval_exp_path, **result_exp_kwargs)\n",
    "    \n",
    "    # Load DemInf demonstration score results.\n",
    "    deminf_result_data = get_deminf_result_data(**eval_exp_kwargs)\n",
    "    if deminf_result_data is not None:\n",
    "        assert np.all(deminf_result_data[\"idxs\"] == train_idxs), \"DemInf experiments do not align.\"\n",
    "        result_data[\"train\"][\"offline_deminf\"] = deminf_result_data[\"scores\"]\n",
    "\n",
    "    # Load rollout results data.\n",
    "    result_data[\"test\"] = get_rollout_scores_result_data(eval_exp_path, **result_exp_kwargs)\n",
    "\n",
    "    # Store return data.\n",
    "    return_data = {\n",
    "        \"train_data\": {\n",
    "            \"dataset\": train_set if return_datasets else None,\n",
    "            \"metadata\": train_set_metadata,\n",
    "            \"scores\": result_data[\"train\"],\n",
    "        },\n",
    "        \"holdout_data\": {\n",
    "            \"dataset\": holdout_set if return_datasets else None,\n",
    "            \"metadata\": holdout_set_metadata,\n",
    "            \"scores\": result_data[\"holdout\"],\n",
    "        },\n",
    "        \"test_data\": {\n",
    "            \"dataset\": test_set if return_datasets else None,\n",
    "            \"metadata\": test_set_metadata,\n",
    "            \"scores\": result_data[\"test\"]\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"cfg\": cfg,\n",
    "            \"policy\": policy if return_policy else None,\n",
    "            \"eval_exp_path\": eval_exp_path,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 1.2: Score results utilities\n",
    "**Description:** Code related to performing operations on loaded demonstration scores (e.g., combining scores across methods) and computing metrics of interest, such as curated dataset quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_normalized_scores(\n",
    "    scores: np.ndarray,\n",
    "    weights: Optional[np.ndarray] = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Return sum of normalized scores.\"\"\"\n",
    "    # Weights for weighted average.\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(scores)) / len(scores)\n",
    "    assert len(weights) == len(scores)\n",
    "\n",
    "    # Remove invalid scores (e.g., all zeros)\n",
    "    mask = scores.sum(axis=1) != 0\n",
    "    scores = scores[mask]\n",
    "    weights = weights[mask] / weights[mask].sum()\n",
    "\n",
    "    # Normalize scores between [0, 1], return weighted average.\n",
    "    def norm(scores: np.ndarray) -> np.ndarray:\n",
    "        return (scores - scores.min()) / (scores.max() - scores.min())\n",
    "    \n",
    "    return np.array([norm(s) * weights[i] for i, s in enumerate(scores)]).sum(axis=0)\n",
    "\n",
    "\n",
    "def compile_demo_quality_scores(\n",
    "    result_data: Dict[str, Any],\n",
    "    exp_keys: List[Union[str, List[str]]],\n",
    "    exp_labels: List[str],\n",
    "    exp_signs: Optional[List[Union[int, List[int]]]] = None,\n",
    "    exp_weights: Optional[List[Union[float, List[float]]]] = None,\n",
    "    split: str = \"train\",\n",
    ") -> Tuple[np.ndarray, List[Union[str, List[str]]], List[str]]:\n",
    "    \"\"\"Compile demonstration quality scores.\"\"\"\n",
    "    # Assume correct sign of scores if none provided.\n",
    "    if exp_signs is None:\n",
    "        exp_signs = [1 for _ in range(len(exp_keys))]\n",
    "    if exp_weights is None:\n",
    "        exp_weights = [1.0 for _ in range(len(exp_keys))]\n",
    "        \n",
    "    demo_quality_scores = []\n",
    "    exp_mask = np.zeros(len(exp_keys), dtype=bool)\n",
    "    for i, (key, sign, weight) in enumerate(zip(exp_keys, exp_signs, exp_weights)):\n",
    "        # Combining multiple score methods.\n",
    "        if isinstance(key, list):            \n",
    "            scores = []\n",
    "            if not isinstance(sign, list):\n",
    "                sign = [sign] * len(key)\n",
    "            if not isinstance(weight, list):\n",
    "                weight = [float(weight) / len(key)] * len(key)\n",
    "            for subkey, subsign in zip(key, sign):\n",
    "                try:\n",
    "                    scores.append(subsign * result_data[f\"{split}_data\"][\"scores\"][subkey])\n",
    "                except KeyError:\n",
    "                    raise ValueError(f\"Cannot handle missing key for combining scores.\")\n",
    "            scores = sum_of_normalized_scores(np.vstack(scores), weights=np.array(weight))\n",
    "        \n",
    "        # Single score method.\n",
    "        else:\n",
    "            try:\n",
    "                scores = sign * result_data[f\"{split}_data\"][\"scores\"][key]\n",
    "            except KeyError:\n",
    "                continue\n",
    "        \n",
    "        assert isinstance(scores, np.ndarray)\n",
    "\n",
    "        # Check if all scores are identical.\n",
    "        if np.all(scores == scores[0]):\n",
    "            print(f\"Identical scores found for {key}.\")\n",
    "            continue\n",
    "\n",
    "        # Store scores.\n",
    "        exp_mask[i] = True\n",
    "        demo_quality_scores.append(scores)\n",
    "\n",
    "    exp_keys = [x for i, x in enumerate(exp_keys) if exp_mask[i]]\n",
    "    exp_labels = [x for i, x in enumerate(exp_labels) if exp_mask[i]]\n",
    "    demo_quality_scores = np.array(demo_quality_scores)\n",
    "    if demo_quality_scores.ndim == 1:\n",
    "        demo_quality_scores = demo_quality_scores[None, :]\n",
    "\n",
    "    return demo_quality_scores, exp_keys, exp_labels\n",
    "\n",
    "\n",
    "def compute_filtered_mean_quality_scores(\n",
    "    result_data: Dict[str, Any],\n",
    "    exp_keys: List[Union[str, List[str]]],\n",
    "    exp_labels: List[str],\n",
    "    exp_signs: Optional[List[Union[int, List[int]]]] = None,\n",
    "    exp_weights: Optional[List[Union[float, List[float]]]] = None,\n",
    "    num_keep: int = 16,\n",
    "    normalize: bool = True,\n",
    "    split: str = \"train\",\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Compute average dataset quality as a function of the number of training demonstrations filtered.\"\"\"\n",
    "    # Compute demo quality scores.\n",
    "    demo_quality_scores, exp_keys, exp_labels = compile_demo_quality_scores(\n",
    "        result_data=result_data,\n",
    "        exp_keys=exp_keys,\n",
    "        exp_labels=exp_labels,\n",
    "        exp_signs=exp_signs,\n",
    "        exp_weights=exp_weights,\n",
    "        split=split,\n",
    "    )\n",
    "\n",
    "    # Sort demonstrations from highest to lowest predicted quality.\n",
    "    quality_labels = result_data[f\"{split}_data\"][\"metadata\"][\"quality_labels\"]\n",
    "    sorted_quality_labels = quality_labels[quality_labels.argsort()][::-1]\n",
    "    sorted_demo_quality_scores_idx = demo_quality_scores.argsort(axis=-1)[:, ::-1]\n",
    "    sorted_quality_preds = [quality_labels[x] for x in sorted_demo_quality_scores_idx]\n",
    "\n",
    "    # Compute average data quality of the filtered set.\n",
    "    mean_quality_fn = lambda x: (np.cumsum(x) / np.arange(1, len(x) + 1))[::-1][:-num_keep]\n",
    "    mean_quality_labels = mean_quality_fn(sorted_quality_labels)\n",
    "    mean_quality_preds = [mean_quality_fn(x) for x in sorted_quality_preds]\n",
    "    random_baseline_pred = np.ones_like(mean_quality_labels) * quality_labels.mean()\n",
    "\n",
    "    # Return result, along with random and oracle.\n",
    "    result = {k: v for k, v in zip(exp_labels, mean_quality_preds)}\n",
    "    result[\"Oracle\"] = mean_quality_labels\n",
    "    result[\"Random\"] = random_baseline_pred\n",
    "\n",
    "    # Optionally normalize scores.\n",
    "    if normalize:\n",
    "        normalize_fn = lambda x: ((x / quality_labels.mean()) - 1.0) * 100\n",
    "        result = {k: normalize_fn(v) for k, v in result.items()}\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_selected_mean_quality_scores(\n",
    "    result_data: Dict[str, Any],\n",
    "    exp_keys: List[Union[str, List[str]]],\n",
    "    exp_labels: List[str],\n",
    "    exp_signs: Optional[List[Union[int, List[int]]]] = None,\n",
    "    exp_weights: Optional[List[Union[float, List[float]]]] = None,\n",
    "    num_keep: int = 20,\n",
    "    normalize: bool = False,\n",
    "    split: str = \"train\",\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Compute average dataset quality as a function of the number of holdout demonstrations selected.\"\"\"\n",
    "    # Compute demo quality scores.\n",
    "    demo_quality_scores, exp_keys, exp_labels = compile_demo_quality_scores(\n",
    "        result_data=result_data,\n",
    "        exp_keys=exp_keys,\n",
    "        exp_labels=exp_labels,\n",
    "        exp_signs=exp_signs,\n",
    "        exp_weights=exp_weights,\n",
    "        split=split,\n",
    "    )\n",
    "\n",
    "    # Sort demonstrations from highest to lowest predicted quality.\n",
    "    quality_labels = result_data[f\"{split}_data\"][\"metadata\"][\"quality_labels\"]\n",
    "    sorted_quality_labels = quality_labels[quality_labels.argsort()][::-1]\n",
    "    sorted_demo_quality_scores_idx = demo_quality_scores.argsort(axis=-1)[:, ::-1]\n",
    "    sorted_quality_preds = [quality_labels[x] for x in sorted_demo_quality_scores_idx]\n",
    "\n",
    "    # Compute average data quality of the selected set.\n",
    "    mean_quality_fn = lambda x: (np.cumsum(x) / np.arange(1, len(x) + 1))[num_keep:]\n",
    "    mean_quality_labels = mean_quality_fn(sorted_quality_labels)\n",
    "    mean_quality_preds = [mean_quality_fn(x) for x in sorted_quality_preds]\n",
    "    random_baseline_pred = np.ones_like(mean_quality_labels) * quality_labels.mean()\n",
    "\n",
    "    # Return result, along with random and oracle.\n",
    "    result = {k: v for k, v in zip(exp_labels, mean_quality_preds)}\n",
    "    result[\"Oracle\"] = mean_quality_labels\n",
    "    result[\"Random\"] = random_baseline_pred\n",
    "\n",
    "    # Optionally normalize scores.\n",
    "    if normalize:\n",
    "        normalize_fn = lambda x: ((x - mean_quality_labels.min()) / (mean_quality_labels.max() - mean_quality_labels.min())) * 100\n",
    "        result = {k: normalize_fn(v) for k, v in result.items()}\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_scores_filter_idxs(\n",
    "    result_data: Dict[str, Any],\n",
    "    split: str,\n",
    "    scores: np.ndarray,\n",
    ") -> List[int]:\n",
    "    \"\"\"Return train mask indices from scores.\"\"\"\n",
    "    assert split in [\"train\", \"holdout\"]\n",
    "    num_eps = result_data[f\"{split}_data\"][\"metadata\"][\"num_eps\"]\n",
    "    train_mask = result_data[f\"{split}_data\"][\"metadata\"][\"demo_mask\"]\n",
    "    valid_idxs = np.where(train_mask == True)[0]\n",
    "    assert num_eps == len(valid_idxs) == len(scores)\n",
    "    \n",
    "    pred_idxs = valid_idxs[scores.argsort()].tolist()\n",
    "    return pred_idxs if split == \"train\" else pred_idxs[::-1]\n",
    "\n",
    "\n",
    "def get_oracle_filter_idxs(\n",
    "    result_data: Dict[str, Any],\n",
    "    split: str,\n",
    "    seed: int,\n",
    ") -> List[int]:\n",
    "    \"\"\"Return oracle quality train mask indices.\"\"\"\n",
    "    assert split in [\"train\", \"holdout\"]\n",
    "    num_eps = result_data[f\"{split}_data\"][\"metadata\"][\"num_eps\"]\n",
    "    train_mask = result_data[f\"{split}_data\"][\"metadata\"][\"demo_mask\"]\n",
    "    valid_idxs = np.where(train_mask == True)[0]\n",
    "    quality_labels = result_data[f\"{split}_data\"][\"metadata\"][\"quality_labels\"]\n",
    "    assert num_eps == len(valid_idxs)\n",
    "\n",
    "    # Randomly shuffle train mask indices before sorting by quality labels.\n",
    "    shuffle_idxs = np.arange(num_eps)\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    rng.shuffle(shuffle_idxs)\n",
    "    valid_idxs: np.ndarray = valid_idxs[shuffle_idxs]\n",
    "    quality_labels: np.ndarray = quality_labels[shuffle_idxs]\n",
    "\n",
    "    # Sort by oracle.\n",
    "    pred_idxs = valid_idxs[quality_labels.argsort()].tolist()\n",
    "    return pred_idxs if split == \"train\" else pred_idxs[::-1]\n",
    "\n",
    "\n",
    "def get_random_filter_idxs(\n",
    "    result_data: Dict[str, Any],\n",
    "    split: str,\n",
    "    seed: int,\n",
    ") -> List[int]:\n",
    "    \"\"\"Return oracle quality train mask indices.\"\"\"\n",
    "    assert split in [\"train\", \"holdout\"]\n",
    "    num_eps = result_data[f\"{split}_data\"][\"metadata\"][\"num_eps\"]\n",
    "    train_mask = result_data[f\"{split}_data\"][\"metadata\"][\"demo_mask\"]\n",
    "    valid_idxs = np.where(train_mask == True)[0]\n",
    "    assert num_eps == len(valid_idxs)\n",
    "\n",
    "    # Randomly shuffle train mask indices.\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    rng.shuffle(valid_idxs)\n",
    "    return valid_idxs.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 1.3: Compile results utilities\n",
    "**Description:** Code related to compiling metrics of interest (e.g., curated dataset quality) across tasks, methods, and seeds for easy visualization/plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_FNS = (\n",
    "    compute_filtered_mean_quality_scores,\n",
    "    compute_selected_mean_quality_scores,\n",
    ")\n",
    "\n",
    "\n",
    "def compile_metric_across_tasks_seeds(\n",
    "    split: str,\n",
    "    tasks: List[str],\n",
    "    seeds: List[int],\n",
    "    policy: str,\n",
    "    train_date: str,\n",
    "    eval_date: str,\n",
    "    result_date: str,\n",
    "    metric_fn: Callable[[Any], Dict[str, np.ndarray]],\n",
    "    real_exp: bool = False,\n",
    ") -> Dict[str, Dict[str, np.ndarray]]:\n",
    "    \"\"\"Return dictionary of compiled results across tasks, methods, and seeds.\"\"\"\n",
    "    compiled_result = defaultdict(dict)\n",
    "    for task in tasks:\n",
    "        task_results = []\n",
    "        for seed in seeds:\n",
    "            load_kwargs = get_load_result_kwargs(\n",
    "                task=task, \n",
    "                policy=policy, \n",
    "                seed=seed,\n",
    "                train_date=train_date,\n",
    "                eval_date=eval_date,\n",
    "                result_date=result_date,\n",
    "            )\n",
    "            result_data = load_result_data(**load_kwargs, real_exp=real_exp)\n",
    "            assert metric_fn in METRIC_FNS or (isinstance(metric_fn, partial) and metric_fn.func in METRIC_FNS)\n",
    "            task_results.append(metric_fn(result_data, split=split))\n",
    "\n",
    "        # Aggregate results by key before stacking.\n",
    "        grouped_task_results = defaultdict(list)\n",
    "        for seed_result in task_results:\n",
    "            for k, v in seed_result.items():\n",
    "                # Note: Demo-SCORE does not work on Lift MH, because the policy does not exhibit failures.  \n",
    "                if \"lift\" in task and \"Demo-SCORE\" in k:\n",
    "                    continue\n",
    "                grouped_task_results[k].append(v)\n",
    "\n",
    "        # Stack results across seeds.\n",
    "        compiled_result[task] = {k: np.vstack(v) for k, v in grouped_task_results.items()}\n",
    " \n",
    "    return compiled_result\n",
    "\n",
    "\n",
    "def save_ranked_demos_to_config(\n",
    "    split: str,\n",
    "    tasks: List[str],\n",
    "    seeds: List[int],\n",
    "    policy: str,\n",
    "    train_date: str,\n",
    "    eval_date: str,\n",
    "    result_date: str,\n",
    "    compile_fn: partial,\n",
    "    real_exp: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"Save yaml configuration file rank-ordering demonstrations based on predicted quality/value.\n",
    "    This configuration file is used to re-train the policy with a curated dataset of demonstrations.\"\"\"\n",
    "    def dict_to_defaultdict(d: Dict[str, Any]) -> defaultdict:\n",
    "        \"\"\"Recursively convert a dictionary to a defaultdict(dict).\"\"\"\n",
    "        return defaultdict(dict, **d) if isinstance(d, dict) else d\n",
    "        \n",
    "    state = \"low_dim\" if \"lowdim\" in policy else \"image\"\n",
    "    for task in tasks:\n",
    "        # Load curation config.\n",
    "        task_curation_config_dir = curation_config_dir / state / task\n",
    "        if not task_curation_config_dir.exists():\n",
    "            task_curation_config_dir.mkdir(parents=True)\n",
    "\n",
    "        config_file = task_curation_config_dir / f\"{split}_config.yaml\"\n",
    "        if config_file.exists():\n",
    "            with open(config_file, mode=\"+r\") as f:\n",
    "                curation_config = dict_to_defaultdict(yaml.safe_load(f))\n",
    "        else:\n",
    "            curation_config = defaultdict(dict)\n",
    "\n",
    "        # Iterate over seeds.\n",
    "        for seed in seeds:\n",
    "            load_kwargs = get_load_result_kwargs(\n",
    "                task=task, \n",
    "                policy=policy, \n",
    "                seed=seed,\n",
    "                train_date=train_date,\n",
    "                eval_date=eval_date,\n",
    "                result_date=result_date,\n",
    "            )\n",
    "            result_data = load_result_data(**load_kwargs, real_exp=real_exp)\n",
    "            \n",
    "            assert isinstance(compile_fn, partial) and compile_fn.func == compile_demo_quality_scores\n",
    "            demo_quality_scores, _, exp_curation_keys = compile_fn(result_data, split=split)\n",
    "            \n",
    "            # Iterate over methods.\n",
    "            if \"_mh\" in task:\n",
    "                curation_config[\"oracle\"][seed] = get_oracle_filter_idxs(result_data, split, seed=seed)\n",
    "            curation_config[\"random\"][seed] = get_random_filter_idxs(result_data, split, seed=seed)\n",
    "            for scores, curation_key in zip(demo_quality_scores, exp_curation_keys):\n",
    "                # Note: Demo-SCORE does not work on Lift MH, because the policy does not exhibit failures. \n",
    "                if \"lift\" in task and \"demoscore\" in curation_key:\n",
    "                    continue\n",
    "                curation_config[curation_key][seed] = get_scores_filter_idxs(result_data, split, scores)\n",
    "        \n",
    "        # Save curation config.\n",
    "        with open(config_file, mode=\"+w\") as f:\n",
    "            yaml.safe_dump(dict(curation_config), f)\n",
    "\n",
    "\n",
    "def compile_last_n_across_tasks_seeds(\n",
    "    tasks: List[str],\n",
    "    seeds: List[int],\n",
    "    policy: str,\n",
    "    curate_dataset: bool = False,\n",
    "    exp_curation_keys: Optional[List[str]] = None,\n",
    "    exp_curation_labels: Optional[List[str]] = None,\n",
    "    filter_ratios: Optional[List[float]] = None,\n",
    "    select_ratios: Optional[List[float]] = None,\n",
    "    get_last_n_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    curation_train_date: str = \"25.03.05\",\n",
    "    reference_train_dates: Optional[Dict[str, str]] = None,\n",
    "    real_exp: bool = False,\n",
    ") -> Dict[str, Dict[str, np.ndarray]]:\n",
    "    \"\"\"Compile last N of a specified training metric across tasks, methods, and seeds.\"\"\"\n",
    "    GET_LAST_N_KWARGS = {\n",
    "        \"diffusion_unet_lowdim_lift_mh\": {\n",
    "            \"n\": 10,\n",
    "            \"required_epochs\": 1000,\n",
    "        },\n",
    "        \"diffusion_unet_lowdim_square_mh\": {\n",
    "            \"n\": 10,\n",
    "            \"required_epochs\": 1000,\n",
    "        },\n",
    "        \"diffusion_unet_lowdim_transport_mh\": {\n",
    "            \"n\": 10,\n",
    "            \"required_epochs\": 1000,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    compiled_result = defaultdict(dict)\n",
    "    for task in tasks:\n",
    "        task_results = []\n",
    "\n",
    "        if get_last_n_kwargs is None:\n",
    "            get_last_n_kwargs = GET_LAST_N_KWARGS[f\"{policy}_{task}\"]\n",
    "\n",
    "        for seed in seeds:\n",
    "            seed_results = defaultdict(list)\n",
    "\n",
    "            # Store default results.\n",
    "            if isinstance(reference_train_dates, dict):\n",
    "                for ref_exp_label, ref_train_date in reference_train_dates.items():\n",
    "                    train_exp_kwargs = get_load_result_kwargs(task, policy, seed, train_date=ref_train_date)[\"train_exp_kwargs\"]\n",
    "                    train_exp_path = get_train_exp_path(**train_exp_kwargs, real_exp=real_exp)\n",
    "                    last_n_metrics = get_last_n_log_keys(train_exp_path, **get_last_n_kwargs)\n",
    "                    seed_results[ref_exp_label].append(last_n_metrics.mean())\n",
    "            \n",
    "            # Store curation results.\n",
    "            if curate_dataset:\n",
    "                assert (\n",
    "                    (exp_curation_keys is not None) and\n",
    "                    (exp_curation_labels is not None) and\n",
    "                    (filter_ratios is not None) and\n",
    "                    (select_ratios is not None)\n",
    "                ), \"Curation arguments must be set together\"\n",
    "\n",
    "                for curation_method, exp_label in zip(exp_curation_keys, exp_curation_labels):\n",
    "                    # Note: Demo-SCORE does not work on Lift MH, because the policy does not exhibit failures. \n",
    "                    if \"lift\" in task and \"demoscore\" in curation_method:\n",
    "                        continue\n",
    "\n",
    "                    for filter_ratio, select_ratio in zip(filter_ratios, select_ratios):\n",
    "                        train_exp_kwargs = get_load_result_kwargs(task, policy, seed, train_date=curation_train_date)[\"train_exp_kwargs\"]\n",
    "                        train_exp_path = get_train_exp_path(\n",
    "                            **train_exp_kwargs, \n",
    "                            curate_dataset=True,\n",
    "                            curation_method=curation_method,\n",
    "                            filter_ratio=filter_ratio,\n",
    "                            select_ratio=select_ratio,\n",
    "                            real_exp=real_exp,\n",
    "                        )\n",
    "                        last_n_metrics = get_last_n_log_keys(train_exp_path, **get_last_n_kwargs)\n",
    "                        seed_results[exp_label].append(last_n_metrics.mean())\n",
    "            \n",
    "            task_results.append(seed_results)\n",
    "\n",
    "        # Aggregate results by key before stacking.\n",
    "        grouped_task_results = defaultdict(list)\n",
    "        for seed_results in task_results:\n",
    "            for k, v in seed_results.items():\n",
    "                grouped_task_results[k].append(v)\n",
    "\n",
    "        # Stack results across seeds.\n",
    "        compiled_result[task] = {k: np.vstack(v) for k, v in grouped_task_results.items()}\n",
    " \n",
    "    return compiled_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 1.4: Plotting utilities\n",
    "**Description:** Code related to plotting, visualization, macros for colors and plot specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_KEEP_FILTERED = 16\n",
    "NUM_KEEP_SELECTED = 40\n",
    "\n",
    "COLOR_SETTINGS = {\n",
    "    # Reference methods.\n",
    "    \"Random\": \"#737373\",                    # Tuned.\n",
    "    \"Oracle\": \"#252525\",                    # Tuned.    \n",
    "    \"All Demos\": \"#66c2a4\",                 # Tuned.\n",
    "    \"Base Policy\": \"#A5856B\",               # Tuned.\n",
    "    \n",
    "    # Offline methods.\n",
    "    \"Policy Loss\": \"#2171b5\",               # Outdated.\n",
    "    \"Policy Uncertainty\": \"#2171b5\",        # Outdated.\n",
    "    \"Action Diversity\": \"#6a51a3\",          # Outdated.\n",
    "    \"State Diversity\": \"#238b45\",           # Outdated.\n",
    "    \"DemInf\": \"#8073ac\",                    # Tuned.\n",
    "\n",
    "    # Online methods.\n",
    "    \"Success Similarity\": \"#41b6c4\",        # Tuned.\n",
    "    \"Demo-SCORE\": \"#045a8d\",                # Tuned.\n",
    "    \n",
    "    # Our methods.\n",
    "    \"CUPID\": \"#ff8c00\",                     # Tuned.\n",
    "    \"CUPID-Quality\": \"#ff5349\",             # Tuned.    \n",
    "}\n",
    "\n",
    "\n",
    "def task_to_subtitle(task: str) -> str:\n",
    "    \"\"\"Return plot subtitle from task string.\"\"\"\n",
    "    parts = task.split(\"_\")\n",
    "    subtitle = None\n",
    "    if len(parts) == 1:\n",
    "        # PushT\n",
    "        if task == \"pusht\":\n",
    "            subtitle = \"PushT\"\n",
    "    elif len(parts) == 2:\n",
    "        # RoboMimic.\n",
    "        if any(x in task for x in [\"lift\", \"square\", \"transport\"]):\n",
    "            subtitle = f\"{parts[0].title()} {parts[1].upper()}\"\n",
    "    elif len(parts) == 3:\n",
    "        # RoboMimic.\n",
    "        if \"tool_hang\" in task:\n",
    "            subtitle = \"ToolHang PH\"\n",
    "        # Hardware standard.\n",
    "        elif \"figure8\" in task:\n",
    "            subtitle = \"Figure-8\"\n",
    "        elif \"tuckbox\" in task:\n",
    "            subtitle = \"TuckBox\"\n",
    "        elif \"bookshelf\" in task:\n",
    "            subtitle = \"Bookshelf\"\n",
    "    elif len(parts) == 4:\n",
    "        # Hardware iterations.\n",
    "        if \"figure8\" in task:\n",
    "            subtitle = \"Figure-8\"\n",
    "        elif \"tuckbox\" in task:\n",
    "            subtitle = \"TuckBox\"\n",
    "        elif \"bookshelf\" in task:\n",
    "            subtitle = \"Bookshelf\"\n",
    "\n",
    "    assert subtitle is not None\n",
    "    return subtitle\n",
    "\n",
    "\n",
    "def get_selected_xticks_xticklabels(num_samples: int, num_selected: int) -> Tuple[np.ndarray, List[str]]:\n",
    "    \"\"\"Return xticks and xticklabels.\"\"\"\n",
    "    xtick_spacing = 10 if num_samples <= 100 else 20\n",
    "    upper_xtick_mod = int(num_samples / 10)\n",
    "    upper_xtick_mod = upper_xtick_mod if upper_xtick_mod % 2 == 0 else upper_xtick_mod - 1\n",
    "    upper_xtick = upper_xtick_mod * 10\n",
    "    xticks = np.linspace(0, upper_xtick, int(upper_xtick / xtick_spacing) + 1)\n",
    "    xtick_labels = [str(int(xtick) + num_selected) for xtick in xticks]\n",
    "    return xticks, xtick_labels\n",
    "\n",
    "\n",
    "def render_mean_filtered_quality_plot(\n",
    "    results: Dict[str, Dict[str, np.ndarray]],\n",
    "    tasks: List[str],\n",
    "    colors: Optional[Dict[str, Any]] = None,\n",
    "    linestyles: Optional[Dict[str, Any]] = None,\n",
    "    label_order: Optional[List[str]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Render average dataset quality as a function of the number of training demonstrations filtered.\"\"\"\n",
    "    # Figure setup.\n",
    "    height, width = 4, 5\n",
    "    fig, axes = plt.subplots(1, len(tasks), figsize=(width * len(tasks), height), dpi=300)\n",
    "    axes = [axes] if len(tasks) == 1 else axes\n",
    "\n",
    "    # Plot results.\n",
    "    handles_labels = {}\n",
    "    for i, (ax, (task, methods)) in enumerate(zip(axes, results.items())):\n",
    "        for method, values in methods.items():\n",
    "            if method in [\"Oracle\", \"Random\"]:\n",
    "                x = np.arange(values.shape[1])\n",
    "                y = values[0]\n",
    "                line, = ax.plot(x, y, label=method, color=COLOR_SETTINGS[method], linestyle=\"--\", linewidth=3)\n",
    "                handles_labels[method] = line\n",
    "\n",
    "        for method, values in methods.items():\n",
    "            if method not in [\"Oracle\", \"Random\"]:\n",
    "                # Custom color and linestyle.\n",
    "                color = colors[method] if colors is not None else COLOR_SETTINGS[method]\n",
    "                linestyle = linestyles[method] if linestyles is not None else \"-\"\n",
    "\n",
    "                x = np.arange(values.shape[1])\n",
    "                y = np.mean(values, axis=0)\n",
    "                y_err = np.std(values, axis=0) / np.sqrt(values.shape[0])\n",
    "                line, = ax.plot(x, y, label=method, color=color, linestyle=linestyle, linewidth=2)\n",
    "                ax.fill_between(x, y - y_err, y + y_err, color=color, alpha=0.2)\n",
    "                handles_labels[method] = line\n",
    "\n",
    "        # Set title and axis labels.\n",
    "        ax.set_title(task_to_subtitle(task), fontsize=16)\n",
    "        ax.set_xlabel(\"Number of Demonstrations Filtered\", fontsize=13.5)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"(%) Increase in Data Quality\", fontsize=13.5)\n",
    "\n",
    "        # Set axis lims.\n",
    "        ax.set_xlim(0, methods[\"Oracle\"].shape[1])\n",
    "        ax.set_ylim(-10, int(methods[\"Oracle\"].max()) + 1)\n",
    "\n",
    "        # Polish spines.\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"bottom\"].set_linewidth(2)\n",
    "        ax.spines[\"left\"].set_linewidth(2)\n",
    "\n",
    "    # Construct legend.\n",
    "    if label_order is not None and isinstance(label_order, list):\n",
    "        handles_labels = {k: handles_labels[k] for k in [\"Oracle\", \"Random\"] + label_order if k in handles_labels}\n",
    "\n",
    "    ncol = len(handles_labels) // 2\n",
    "    ncol = ncol if len(handles_labels) % 2 == 0 else ncol + 1\n",
    "    fig.legend(\n",
    "        handles_labels.values(), \n",
    "        handles_labels.keys(),\n",
    "        loc=\"upper center\", \n",
    "        fontsize=10, \n",
    "        ncol=ncol,\n",
    "        bbox_to_anchor=(0.5, 0.0), \n",
    "        frameon=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def render_mean_selected_quality_plot(\n",
    "    results: Dict[str, Dict[str, np.ndarray]],\n",
    "    tasks: List[str],\n",
    "    colors: Optional[Dict[str, Any]] = None,\n",
    "    linestyles: Optional[Dict[str, Any]] = None,\n",
    "    label_order: Optional[List[str]] = None,\n",
    "    auto_ylims: bool = False,\n",
    "    num_keep_selected: int = NUM_KEEP_SELECTED\n",
    ") -> None:\n",
    "    \"\"\"Render average dataset quality as a function of the number of holdout demonstrations selected.\"\"\"\n",
    "    # Figure setup.\n",
    "    height, width = 4, 5\n",
    "    fig, axes = plt.subplots(1, len(tasks), figsize=(width * len(tasks), height), dpi=300)\n",
    "    axes = [axes] if len(tasks) == 1 else axes\n",
    "\n",
    "    # Plot results.\n",
    "    handles_labels = {}\n",
    "    for i, (ax, (task, methods)) in enumerate(zip(axes, results.items())):\n",
    "        for method, values in methods.items():\n",
    "            if method in [\"Oracle\", \"Random\"]:\n",
    "                x = np.arange(values.shape[1])\n",
    "                y = values[0]\n",
    "                line, = ax.plot(x, y, label=method, color=COLOR_SETTINGS[method], linestyle=\"--\", linewidth=3)\n",
    "                handles_labels[method] = line\n",
    "\n",
    "        for method, values in methods.items():\n",
    "            if method not in [\"Oracle\", \"Random\"]:\n",
    "                # Custom color and linestyle.\n",
    "                color = colors[method] if colors is not None else COLOR_SETTINGS[method]\n",
    "                linestyle = linestyles[method] if linestyles is not None else \"-\"\n",
    "\n",
    "                x = np.arange(values.shape[1])\n",
    "                y = np.mean(values, axis=0)\n",
    "                y_err = np.std(values, axis=0) / np.sqrt(values.shape[0])\n",
    "                line, = ax.plot(x, y, label=method, color=color, linestyle=linestyle, linewidth=2)\n",
    "                ax.fill_between(x, y - y_err, y + y_err, color=color, alpha=0.2)\n",
    "                handles_labels[method] = line\n",
    "\n",
    "        # Set title and axis labels.\n",
    "        ax.set_title(task_to_subtitle(task), fontsize=16)\n",
    "        ax.set_xlabel(\"Number of Demonstrations Selected\", fontsize=13.5)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Average Selected Quality\", fontsize=13.5)\n",
    "                \n",
    "        # Set axis lims.\n",
    "        ax.set_xlim(0, methods[\"Oracle\"].shape[1])\n",
    "        if not auto_ylims:\n",
    "            if \"transport\" in task:\n",
    "                ax.set_ylim(2.025, 3.02)\n",
    "            else:\n",
    "                ax.set_ylim(1.9, 3.02)\n",
    "        \n",
    "        # Set axis ticks.\n",
    "        xticks, xticklabels = get_selected_xticks_xticklabels(methods[\"Oracle\"].shape[1], num_keep_selected)\n",
    "        ax.set_xticks(xticks)\n",
    "        ax.set_xticklabels(xticklabels)\n",
    "\n",
    "        # Polish spines.\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"bottom\"].set_linewidth(2)\n",
    "        ax.spines[\"left\"].set_linewidth(2)\n",
    "\n",
    "    # Construct legend.\n",
    "    if label_order is not None and isinstance(label_order, list):\n",
    "        handles_labels = {k: handles_labels[k] for k in [\"Oracle\", \"Random\"] + label_order if k in handles_labels}\n",
    "\n",
    "    ncol = len(handles_labels) // 2\n",
    "    ncol = ncol if len(handles_labels) % 2 == 0 else ncol + 1\n",
    "    fig.legend(\n",
    "        handles_labels.values(), \n",
    "        handles_labels.keys(),\n",
    "        loc=\"upper center\", \n",
    "        fontsize=10, \n",
    "        ncol=ncol,\n",
    "        bbox_to_anchor=(0.5, 0.0), \n",
    "        frameon=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def render_curation_retraining_plot(\n",
    "    results: Dict[str, Dict[str, np.ndarray]],\n",
    "    tasks: List[str],\n",
    "    curation_ratios: List[float],\n",
    "    xlabel: str = \"Fraction of Dataset Filtered\",\n",
    "    colors: Optional[Dict[str, Any]] = None,\n",
    "    label_order: Optional[List[str]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Render policy success rate as a function of the number of demonstrations filtered or selected.\"\"\"\n",
    "    # Figure setup.\n",
    "    height, width = 4, 5\n",
    "    fig, axes = plt.subplots(1, len(tasks), figsize=(width * len(tasks), height), dpi=300)\n",
    "    axes = [axes] if len(tasks) == 1 else axes\n",
    "\n",
    "    # Axis lim params.\n",
    "    xmargin = 0.025\n",
    "    ymargin = 0.050\n",
    "    xmin = max(curation_ratios[0] - xmargin, 0)\n",
    "    xmax = min(curation_ratios[-1] + xmargin, 1)\n",
    "    hxmin = max(curation_ratios[0] - xmargin * 0.5, 0)\n",
    "    hxmax = min(curation_ratios[-1] + xmargin * 0.5, 1)\n",
    "\n",
    "    # Plot results.\n",
    "    handles_labels = {}\n",
    "    for i, (ax, (task, methods)) in enumerate(zip(axes, results.items())):\n",
    "        \n",
    "        # Track for ylims.\n",
    "        ymin = float(\"inf\")\n",
    "        ymax = float(\"-inf\")\n",
    "        \n",
    "        for method, values in methods.items():\n",
    "            if method == \"All Demos\":\n",
    "                assert values.squeeze().ndim == 1\n",
    "                y = values.mean()\n",
    "                handles_labels[method] = ax.axhline(y=y, color=COLOR_SETTINGS[method], linestyle=\"--\", linewidth=5)\n",
    "                \n",
    "                # Update ymin and ymax.\n",
    "                ymin = min(ymin, y)\n",
    "                ymax = max(ymax, y)\n",
    "        \n",
    "        for method, values in methods.items():\n",
    "            if method == \"Base Policy\":\n",
    "                assert values.squeeze().ndim == 1\n",
    "                y = values.mean()\n",
    "                handles_labels[method] = ax.axhline(y=y, color=COLOR_SETTINGS[method], linestyle=\"--\", linewidth=5)\n",
    "                \n",
    "                # Update ymin and ymax.\n",
    "                ymin = min(ymin, y)\n",
    "                ymax = max(ymax, y)\n",
    "        \n",
    "        for method, values in methods.items():\n",
    "            if method in [\"Oracle\", \"Random\"]:\n",
    "                assert values.squeeze().ndim == 2\n",
    "                x = np.array(curation_ratios)\n",
    "                y = values.mean(axis=0)\n",
    "                line, = ax.plot(x, y, color=COLOR_SETTINGS[method], linestyle=\"--\", linewidth=3, marker=\"o\", markersize=8)\n",
    "                handles_labels[method] = line\n",
    "\n",
    "                # Update ymin and ymax.\n",
    "                ymin = min(ymin, y.min())\n",
    "                ymax = max(ymax, y.max())\n",
    "\n",
    "        for method, values in methods.items():\n",
    "            if method not in [\"All Demos\", \"Base Policy\", \"Oracle\", \"Random\"]:\n",
    "                # Custom color and linestyle.\n",
    "                color = colors[method] if colors is not None else COLOR_SETTINGS[method]\n",
    "                \n",
    "                assert values.squeeze().ndim == 2\n",
    "                x = np.array(curation_ratios)\n",
    "                y = values.mean(axis=0)\n",
    "                y_err = values.std(axis=0) / np.sqrt(values.shape[0])\n",
    "                line, = ax.plot(x, y, color=color, linestyle=\"-\", linewidth=3, marker=\"o\", markersize=10, markeredgecolor='white', markeredgewidth=2)\n",
    "                ax.fill_between(x, y - y_err, y + y_err, color=color, alpha=0.25)\n",
    "                handles_labels[method] = line\n",
    "\n",
    "                # Update ymin and ymax.\n",
    "                ymin = min(ymin, y.min())\n",
    "                ymax = max(ymax, y.max())\n",
    "\n",
    "        # Set title and axis labels.\n",
    "        ax.set_title(task_to_subtitle(task), fontsize=16)\n",
    "        ax.set_xlabel(xlabel, fontsize=13.5)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Success Rate\", fontsize=13.5)\n",
    "        \n",
    "        # Set axis lims.\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_ylim(max(ymin - ymargin, -0.01), min(ymax + ymargin, 1.01))\n",
    "\n",
    "        # Set axis ticks.\n",
    "        ax.set_xticks(curation_ratios)\n",
    "        ax.set_xticklabels([f\"{r:.2f}\" for r in curation_ratios])\n",
    "\n",
    "        # Polish spines.\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"bottom\"].set_linewidth(2)\n",
    "        ax.spines[\"left\"].set_linewidth(2)\n",
    "    \n",
    "    # Set ygrid.\n",
    "    for ax in axes:\n",
    "        ax.hlines(y=ax.get_yticks(), xmin=hxmin, xmax=hxmax, colors=\"gray\", linestyles=\"-\", linewidth=0.5, alpha=0.5, zorder=0)\n",
    "\n",
    "    # Construct legend.\n",
    "    if label_order is not None and isinstance(label_order, list):\n",
    "        _handles_labels = {k: handles_labels[k] for k in label_order if k in handles_labels}\n",
    "        if \"Base Policy\" in handles_labels:\n",
    "            _handles_labels[\"Base Policy\"] = handles_labels[\"Base Policy\"]\n",
    "        if \"All Demos\" in handles_labels:\n",
    "            _handles_labels[\"All Demos\"] = handles_labels[\"All Demos\"]\n",
    "        handles_labels = _handles_labels\n",
    "\n",
    "    ncol = len(handles_labels) // 2\n",
    "    ncol = ncol if len(handles_labels) % 2 == 0 else ncol + 1\n",
    "    fig.legend(\n",
    "        handles_labels.values(), \n",
    "        handles_labels.keys(),\n",
    "        loc=\"upper center\", \n",
    "        fontsize=10, \n",
    "        ncol=ncol,\n",
    "        bbox_to_anchor=(0.5, 0.0),\n",
    "        frameon=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 2: Visualize data quality results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 2.1: RoboMimic demo filtering (Task 1: Filter-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adjust to match your experiment dates.\n",
    "eval_date=\"<enter_policy_eval_date>\"\n",
    "train_date=\"<enter_policy_train_date>\"\n",
    "result_date=\"default\"\n",
    "\n",
    "# TODO: Adjust to your intended policy state.\n",
    "state = \"lowdim\" \n",
    "# state = \"image\"\n",
    "\n",
    "# TODO: Adjust to your intended tasks and seeds.\n",
    "tasks = [\"lift_mh\"]  # tasks = [\"lift_mh\", \"square_mh\", \"transport_mh\"]\n",
    "seeds = [0, 1, 2]\n",
    "policy = f\"diffusion_unet_{state}\"\n",
    "\n",
    "# TODO: Adjust to your intended methods.\n",
    "exp_metadata = {\n",
    "\n",
    "    ######################## Custom baselines. ########################\n",
    "    # \"Policy Loss\": {\n",
    "    #     \"key\": \"offline_policy_loss\",\n",
    "    #     \"curation_key\": \"policy_loss\",\n",
    "    #     \"sign\": -1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    # \"Action Diversity\": {\n",
    "    #     \"key\": \"offline_action_diversity\",\n",
    "    #     \"curation_key\": \"action_diversity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    # \"State Diversity\": {\n",
    "    #     \"key\": get_offline_state_diversity_exp_key(\n",
    "    #         embedding_name=\"policy\",\n",
    "    #         score_fn=\"mahal\",\n",
    "    #         method_prefix=True,\n",
    "    #     ),\n",
    "    #     \"curation_key\": \"state_diversity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    ######################## Key baselines. ########################\n",
    "    # \"Demo-SCORE\": {\n",
    "    #     \"key\": \"online_demo_score\",\n",
    "    #     \"curation_key\": \"demoscore\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "    \n",
    "    # \"Success Similarity\": {\n",
    "    #     \"key\": get_online_state_similarity_exp_key(\n",
    "    #         embedding_name=\"policy\",\n",
    "    #         score_fn=\"l2\",\n",
    "    #         aggr_fn=\"mean_of_mean_success\",\n",
    "    #         metric=\"net\",\n",
    "    #         num_rollouts=\"all\",\n",
    "    #         method_prefix=True,\n",
    "    #     ),\n",
    "    #     \"curation_key\": \"state_similarity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    # \"DemInf\": {\n",
    "    #     \"key\": \"offline_deminf\",\n",
    "    #     \"curation_key\": \"deminf\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    ######################## Our methods. ########################\n",
    "    \"CUPID\": {\n",
    "        \"key\": get_online_trak_influence_exp_key(\n",
    "            aggr_fn=\"sum_of_sum\",\n",
    "            metric=\"net\",\n",
    "            num_rollouts=\"all\",\n",
    "            method_prefix=True,\n",
    "        ),\n",
    "        \"curation_key\": \"influence_sum_official\",\n",
    "        \"sign\": 1,\n",
    "        \"weight\": 1, \n",
    "    },\n",
    "\n",
    "    \"CUPID-Quality\": {\n",
    "        \"key\": get_online_trak_influence_quality_exp_key(\n",
    "            aggr_fn=\"sum_of_sum\",\n",
    "            metric=\"net\",\n",
    "            num_rollouts=\"all\",\n",
    "        ),\n",
    "        \"curation_key\": \"influence_quality_official\",\n",
    "        \"sign\": 1,\n",
    "        \"weight\": [0.50, 0.25, 0.25], \n",
    "    },\n",
    "}\n",
    "exp_labels = list(exp_metadata.keys())\n",
    "exp_keys = [exp_metadata[k][\"key\"] for k in exp_labels]\n",
    "exp_curation_keys = [exp_metadata[k][\"curation_key\"] for k in exp_labels]\n",
    "exp_signs = [exp_metadata[k][\"sign\"] for k in exp_labels]\n",
    "exp_weights = [exp_metadata[k][\"weight\"] for k in exp_labels]\n",
    "assert len(exp_labels) == len(exp_keys) == len(exp_curation_keys) == len(exp_signs) == len(exp_weights)\n",
    "\n",
    "# Plot data quality result.\n",
    "metric_fn = partial(\n",
    "    compute_filtered_mean_quality_scores,\n",
    "    exp_keys=exp_keys,\n",
    "    exp_labels=exp_labels,\n",
    "    exp_signs=exp_signs,\n",
    "    exp_weights=exp_weights,\n",
    "    num_keep=NUM_KEEP_FILTERED,\n",
    ")\n",
    "filter_results = compile_metric_across_tasks_seeds(\n",
    "    split=\"train\",\n",
    "    tasks=tasks,\n",
    "    seeds=seeds,\n",
    "    policy=policy,\n",
    "    train_date=train_date,\n",
    "    eval_date=eval_date,\n",
    "    result_date=result_date,\n",
    "    metric_fn=metric_fn,\n",
    ")\n",
    "render_mean_filtered_quality_plot(\n",
    "    results=filter_results,\n",
    "    tasks=tasks,\n",
    "    label_order=[\"Oracle\", \"Random\", \"Policy Loss\", \"State Diversity\", \"Action Diversity\", \"Demo-SCORE\", \"Success Similarity\", \"DemInf\", \"CUPID\", \"CUPID-Quality\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 2.2: RoboMimic demo selection (Task 2: Select-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adjust to match your experiment dates.\n",
    "eval_date=\"<enter_policy_eval_date>\"\n",
    "train_date=\"<enter_policy_train_date>\"\n",
    "result_date=\"default\"\n",
    "\n",
    "# TODO: Adjust to your intended policy state.\n",
    "state = \"lowdim\" \n",
    "# state = \"image\"\n",
    "\n",
    "# TODO: Adjust to your intended tasks and seeds.\n",
    "tasks = [\"lift_mh\"]  # tasks = [\"lift_mh\", \"square_mh\", \"transport_mh\"]\n",
    "seeds = [0, 1, 2]\n",
    "policy = f\"diffusion_unet_{state}\"\n",
    "\n",
    "# TODO: Adjust to your intended methods.\n",
    "exp_metadata = {\n",
    "    \n",
    "    ######################## Custom baselines. ########################\n",
    "    # \"Policy Uncertainty\": {\n",
    "    #     \"key\": \"offline_policy_loss\",\n",
    "    #     \"curation_key\": \"policy_uncertainty\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    # \"Action Diversity\": {\n",
    "    #     \"key\": \"offline_action_diversity\",\n",
    "    #     \"curation_key\": \"action_diversity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    # \"State Diversity\": {\n",
    "    #     \"key\": get_offline_state_diversity_exp_key(\n",
    "    #         embedding_name=\"policy\",\n",
    "    #         score_fn=\"mahal\",\n",
    "    #         method_prefix=True,\n",
    "    #     ),\n",
    "    #     \"curation_key\": \"state_diversity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    ######################## Key baselines. ########################\n",
    "    # \"Demo-SCORE\": {\n",
    "    #     \"key\": \"online_demo_score\",\n",
    "    #     \"curation_key\": \"demoscore\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "    \n",
    "    # \"Success Similarity\": {\n",
    "    #     \"key\": get_online_state_similarity_exp_key(\n",
    "    #         embedding_name=\"policy\",\n",
    "    #         score_fn=\"l2\",\n",
    "    #         aggr_fn=\"mean_of_mean_success\",\n",
    "    #         metric=\"net\",\n",
    "    #         num_rollouts=\"all\",\n",
    "    #         method_prefix=True,\n",
    "    #     ),\n",
    "    #     \"curation_key\": \"state_similarity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    ######################## Our methods. ########################\n",
    "    \"CUPID\": {\n",
    "        \"key\": get_online_trak_influence_exp_key(\n",
    "            aggr_fn=\"sum_of_sum\",\n",
    "            metric=\"net\",\n",
    "            num_rollouts=\"all\",\n",
    "            method_prefix=True,\n",
    "        ),\n",
    "        \"curation_key\": \"influence_sum_official\",\n",
    "        \"sign\": 1,\n",
    "        \"weight\": 1, \n",
    "    },\n",
    "\n",
    "    \"CUPID-Quality\": {\n",
    "        \"key\": get_online_trak_influence_quality_exp_key(\n",
    "            aggr_fn=\"sum_of_sum\",\n",
    "            metric=\"net\",\n",
    "            num_rollouts=\"all\",\n",
    "        ),\n",
    "        \"curation_key\": \"influence_quality_official\",\n",
    "        \"sign\": 1,\n",
    "        \"weight\": [0.50, 0.25, 0.25], \n",
    "    },\n",
    "}\n",
    "exp_labels = list(exp_metadata.keys())\n",
    "exp_keys = [exp_metadata[k][\"key\"] for k in exp_labels]\n",
    "exp_curation_keys = [exp_metadata[k][\"curation_key\"] for k in exp_labels]\n",
    "exp_signs = [exp_metadata[k][\"sign\"] for k in exp_labels]\n",
    "exp_weights = [exp_metadata[k][\"weight\"] for k in exp_labels]\n",
    "assert len(exp_keys) == len(exp_labels) == len(exp_curation_keys) == len(exp_signs) == len(exp_weights)\n",
    "\n",
    "# Plot data quality result.\n",
    "metric_fn = partial(\n",
    "    compute_selected_mean_quality_scores,\n",
    "    exp_keys=exp_keys,\n",
    "    exp_labels=exp_labels,\n",
    "    exp_signs=exp_signs,\n",
    "    exp_weights=exp_weights,\n",
    "    num_keep=NUM_KEEP_SELECTED,\n",
    ")\n",
    "select_results = compile_metric_across_tasks_seeds(\n",
    "    split=\"holdout\",\n",
    "    tasks=tasks,\n",
    "    seeds=seeds,\n",
    "    policy=policy,\n",
    "    train_date=train_date,\n",
    "    eval_date=eval_date,\n",
    "    result_date=result_date,\n",
    "    metric_fn=metric_fn,\n",
    ")\n",
    "render_mean_selected_quality_plot(\n",
    "    results=select_results,\n",
    "    tasks=tasks,\n",
    "    label_order=[\"Oracle\", \"Random\", \"Policy Loss\", \"State Diversity\", \"Action Diversity\", \"Demo-SCORE\", \"Success Similarity\", \"DemInf\", \"CUPID\", \"CUPID-Quality\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 3: Generate config files for curated re-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 3.1: RoboMimic demo filtering (Task 1: Filter-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adjust to match your experiment dates.\n",
    "eval_date=\"<enter_policy_eval_date>\"\n",
    "train_date=\"<enter_policy_train_date>\"\n",
    "result_date=\"default\"\n",
    "\n",
    "# TODO: Adjust to your intended policy state.\n",
    "state = \"lowdim\" \n",
    "# state = \"image\"\n",
    "\n",
    "# TODO: Adjust to your intended tasks and seeds.\n",
    "tasks = [\"lift_mh\"]  # tasks = [\"lift_mh\", \"square_mh\", \"transport_mh\"]\n",
    "seeds = [0, 1, 2]\n",
    "policy = f\"diffusion_unet_{state}\"\n",
    "\n",
    "# TODO: Adjust to your intended methods.\n",
    "exp_metadata = {\n",
    "\n",
    "    ######################## Custom baselines. ########################\n",
    "    # \"Policy Loss\": {\n",
    "    #     \"key\": \"offline_policy_loss\",\n",
    "    #     \"curation_key\": \"policy_loss\",\n",
    "    #     \"sign\": -1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    # \"Action Diversity\": {\n",
    "    #     \"key\": \"offline_action_diversity\",\n",
    "    #     \"curation_key\": \"action_diversity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    # \"State Diversity\": {\n",
    "    #     \"key\": get_offline_state_diversity_exp_key(\n",
    "    #         embedding_name=\"policy\",\n",
    "    #         score_fn=\"mahal\",\n",
    "    #         method_prefix=True,\n",
    "    #     ),\n",
    "    #     \"curation_key\": \"state_diversity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    ######################## Key baselines. ########################\n",
    "    # \"Demo-SCORE\": {\n",
    "    #     \"key\": \"online_demo_score\",\n",
    "    #     \"curation_key\": \"demoscore\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "    \n",
    "    # \"Success Similarity\": {\n",
    "    #     \"key\": get_online_state_similarity_exp_key(\n",
    "    #         embedding_name=\"policy\",\n",
    "    #         score_fn=\"l2\",\n",
    "    #         aggr_fn=\"mean_of_mean_success\",\n",
    "    #         metric=\"net\",\n",
    "    #         num_rollouts=\"all\",\n",
    "    #         method_prefix=True,\n",
    "    #     ),\n",
    "    #     \"curation_key\": \"state_similarity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    # \"DemInf\": {\n",
    "    #     \"key\": \"offline_deminf\",\n",
    "    #     \"curation_key\": \"deminf\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    ######################## Our methods. ########################\n",
    "    \"CUPID\": {\n",
    "        \"key\": get_online_trak_influence_exp_key(\n",
    "            aggr_fn=\"sum_of_sum\",\n",
    "            metric=\"net\",\n",
    "            num_rollouts=\"all\",\n",
    "            method_prefix=True,\n",
    "        ),\n",
    "        \"curation_key\": \"influence_sum_official\",\n",
    "        \"sign\": 1,\n",
    "        \"weight\": 1, \n",
    "    },\n",
    "\n",
    "    \"CUPID-Quality\": {\n",
    "        \"key\": get_online_trak_influence_quality_exp_key(\n",
    "            aggr_fn=\"sum_of_sum\",\n",
    "            metric=\"net\",\n",
    "            num_rollouts=\"all\",\n",
    "        ),\n",
    "        \"curation_key\": \"influence_quality_official\",\n",
    "        \"sign\": 1,\n",
    "        \"weight\": [0.50, 0.25, 0.25], \n",
    "    },\n",
    "}\n",
    "exp_labels = list(exp_metadata.keys())\n",
    "exp_keys = [exp_metadata[k][\"key\"] for k in exp_labels]\n",
    "exp_curation_keys = [exp_metadata[k][\"curation_key\"] for k in exp_labels]\n",
    "exp_signs = [exp_metadata[k][\"sign\"] for k in exp_labels]\n",
    "exp_weights = [exp_metadata[k][\"weight\"] for k in exp_labels]\n",
    "assert len(exp_labels) == len(exp_keys) == len(exp_curation_keys) == len(exp_signs) == len(exp_weights)\n",
    "\n",
    "# Generate curation config.\n",
    "compile_fn = partial(\n",
    "    compile_demo_quality_scores,\n",
    "    exp_keys=exp_keys,\n",
    "    exp_labels=exp_curation_keys,\n",
    "    exp_signs=exp_signs,\n",
    "    exp_weights=exp_weights,\n",
    ")\n",
    "save_ranked_demos_to_config(\n",
    "    split=\"train\",\n",
    "    tasks=tasks,\n",
    "    seeds=seeds,\n",
    "    policy=policy,\n",
    "    train_date=train_date,\n",
    "    eval_date=eval_date,\n",
    "    result_date=result_date,\n",
    "    compile_fn=compile_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 3.2: RoboMimic demo selection (Task 2: Select-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adjust to match your experiment dates.\n",
    "eval_date=\"<enter_policy_eval_date>\"\n",
    "train_date=\"<enter_policy_train_date>\"\n",
    "result_date=\"default\"\n",
    "\n",
    "# TODO: Adjust to your intended policy state.\n",
    "state = \"lowdim\" \n",
    "# state = \"image\"\n",
    "\n",
    "# TODO: Adjust to your intended tasks and seeds.\n",
    "tasks = [\"lift_mh\"]  # tasks = [\"lift_mh\", \"square_mh\", \"transport_mh\"]\n",
    "seeds = [0, 1, 2]\n",
    "policy = f\"diffusion_unet_{state}\"\n",
    "\n",
    "# TODO: Adjust to your intended methods.\n",
    "exp_metadata = {\n",
    "    \n",
    "    ######################## Custom baselines. ########################\n",
    "    # \"Policy Uncertainty\": {\n",
    "    #     \"key\": \"offline_policy_loss\",\n",
    "    #     \"curation_key\": \"policy_uncertainty\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    # \"Action Diversity\": {\n",
    "    #     \"key\": \"offline_action_diversity\",\n",
    "    #     \"curation_key\": \"action_diversity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    # \"State Diversity\": {\n",
    "    #     \"key\": get_offline_state_diversity_exp_key(\n",
    "    #         embedding_name=\"policy\",\n",
    "    #         score_fn=\"mahal\",\n",
    "    #         method_prefix=True,\n",
    "    #     ),\n",
    "    #     \"curation_key\": \"state_diversity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    ######################## Key baselines. ########################\n",
    "    # \"Demo-SCORE\": {\n",
    "    #     \"key\": \"online_demo_score\",\n",
    "    #     \"curation_key\": \"demoscore\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "    \n",
    "    # \"Success Similarity\": {\n",
    "    #     \"key\": get_online_state_similarity_exp_key(\n",
    "    #         embedding_name=\"policy\",\n",
    "    #         score_fn=\"l2\",\n",
    "    #         aggr_fn=\"mean_of_mean_success\",\n",
    "    #         metric=\"net\",\n",
    "    #         num_rollouts=\"all\",\n",
    "    #         method_prefix=True,\n",
    "    #     ),\n",
    "    #     \"curation_key\": \"state_similarity\",\n",
    "    #     \"sign\": 1,\n",
    "    #     \"weight\": 1, \n",
    "    # },\n",
    "\n",
    "    ######################## Our methods. ########################\n",
    "    \"CUPID\": {\n",
    "        \"key\": get_online_trak_influence_exp_key(\n",
    "            aggr_fn=\"sum_of_sum\",\n",
    "            metric=\"net\",\n",
    "            num_rollouts=\"all\",\n",
    "            method_prefix=True,\n",
    "        ),\n",
    "        \"curation_key\": \"influence_sum_official\",\n",
    "        \"sign\": 1,\n",
    "        \"weight\": 1, \n",
    "    },\n",
    "\n",
    "    \"CUPID-Quality\": {\n",
    "        \"key\": get_online_trak_influence_quality_exp_key(\n",
    "            aggr_fn=\"sum_of_sum\",\n",
    "            metric=\"net\",\n",
    "            num_rollouts=\"all\",\n",
    "        ),\n",
    "        \"curation_key\": \"influence_quality_official\",\n",
    "        \"sign\": 1,\n",
    "        \"weight\": [0.50, 0.25, 0.25], \n",
    "    },\n",
    "}\n",
    "exp_labels = list(exp_metadata.keys())\n",
    "exp_keys = [exp_metadata[k][\"key\"] for k in exp_labels]\n",
    "exp_curation_keys = [exp_metadata[k][\"curation_key\"] for k in exp_labels]\n",
    "exp_signs = [exp_metadata[k][\"sign\"] for k in exp_labels]\n",
    "exp_weights = [exp_metadata[k][\"weight\"] for k in exp_labels]\n",
    "assert len(exp_keys) == len(exp_labels) == len(exp_curation_keys) == len(exp_signs) == len(exp_weights)\n",
    "\n",
    "# Generate curation config.\n",
    "compile_fn = partial(\n",
    "    compile_demo_quality_scores,\n",
    "    exp_keys=exp_keys,\n",
    "    exp_labels=exp_curation_keys,\n",
    "    exp_signs=exp_signs,\n",
    "    exp_weights=exp_weights,\n",
    ")\n",
    "\n",
    "save_ranked_demos_to_config(\n",
    "    split=\"holdout\",\n",
    "    tasks=tasks,\n",
    "    seeds=seeds,\n",
    "    policy=policy,\n",
    "    train_date=train_date,\n",
    "    eval_date=eval_date,\n",
    "    result_date=result_date,\n",
    "    compile_fn=compile_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 4: Visualize policy performance after curated re-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 4.1: RoboMimic demo filtering (Task 1: Filter-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adjust to match your experiment dates.\n",
    "reference_train_dates = {\"All Demos\": \"<enter_policy_train_date>\"}  # Train date of original policy. \n",
    "curation_train_date = \"<enter_policy_retrain_date>\"                 # Train date of curated policy.\n",
    "\n",
    "# TODO: Adjust to your intended policy state.\n",
    "state = \"lowdim\" \n",
    "# state = \"image\"\n",
    "\n",
    "# TODO: Adjust to your intended tasks and seeds.\n",
    "tasks = [\"lift_mh\"]  # tasks = [\"lift_mh\", \"square_mh\", \"transport_mh\"]\n",
    "seeds = [0, 1, 2]\n",
    "policy = f\"diffusion_unet_{state}\"\n",
    "\n",
    "# Plot policy performance result.\n",
    "plot_curation_keys = [\n",
    "    \"oracle\",\n",
    "    \"random\",\n",
    "    # \"policy_loss\",\n",
    "    # \"state_diversity\",\n",
    "    # \"action_diversity\",\n",
    "    # \"deminf\",\n",
    "    # \"state_similarity\",\n",
    "    # \"demoscore\",\n",
    "    \"influence_sum_official\",\n",
    "    \"influence_quality_official\",\n",
    "]\n",
    "plot_curation_labels = [\n",
    "    \"Oracle\",\n",
    "    \"Random\",\n",
    "    # \"Policy Loss\",\n",
    "    # \"State Diversity\",\n",
    "    # \"Action Diversity\",\n",
    "    # \"DemInf\",\n",
    "    # \"Success Similarity\",\n",
    "    # \"Demo-SCORE\",\n",
    "    \"CUPID\",\n",
    "    \"CUPID-Quality\",\n",
    "]\n",
    "filter_ratios = [0.10, 0.25, 0.50, 0.75, 0.90]\n",
    "select_ratios = [0.00, 0.00, 0.00, 0.00, 0.00]\n",
    "\n",
    "results = compile_last_n_across_tasks_seeds(\n",
    "    tasks=tasks,\n",
    "    seeds=seeds,\n",
    "    policy=policy,\n",
    "    curate_dataset=True,\n",
    "    exp_curation_keys=plot_curation_keys,\n",
    "    exp_curation_labels=plot_curation_labels,\n",
    "    filter_ratios=filter_ratios,\n",
    "    select_ratios=select_ratios,\n",
    "    curation_train_date=curation_train_date,\n",
    "    reference_train_dates=reference_train_dates,\n",
    ")\n",
    "render_curation_retraining_plot(\n",
    "    results=results,\n",
    "    tasks=tasks,\n",
    "    curation_ratios=filter_ratios,\n",
    "    label_order=plot_curation_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 4.2: RoboMimic demo selection (Task 2: Select-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adjust to match your experiment dates.\n",
    "reference_train_dates = {       \n",
    "    \"Base Policy\": \"<enter_policy_train_date>\",              # Train date of original policy. \n",
    "    \"All Demos\": \"<optional_enter_full_policy_train_date>\",  # Train date of policy trained with all 300 demos. \n",
    "}\n",
    "curation_train_date = \"<enter_policy_retrain_date>\"          # Train date of curated policy.\n",
    "\n",
    "# TODO: Adjust to your intended policy state.\n",
    "state = \"lowdim\" \n",
    "# state = \"image\"\n",
    "\n",
    "# TODO: Adjust to your intended tasks and seeds.\n",
    "tasks = [\"lift_mh\"]  # tasks = [\"lift_mh\", \"square_mh\", \"transport_mh\"]\n",
    "seeds = [0, 1, 2]\n",
    "policy = f\"diffusion_unet_{state}\"\n",
    "\n",
    "# Plot policy performance result.\n",
    "plot_curation_keys = [\n",
    "    \"oracle\",\n",
    "    \"random\",\n",
    "    # \"policy_loss\",\n",
    "    # \"state_diversity\",\n",
    "    # \"action_diversity\",\n",
    "    # \"state_similarity\",\n",
    "    # \"demoscore\",\n",
    "    \"influence_sum_official\",\n",
    "    \"influence_quality_official\",\n",
    "]\n",
    "plot_curation_labels = [\n",
    "    \"Oracle\",\n",
    "    \"Random\",\n",
    "    # \"Policy Loss\",\n",
    "    # \"State Diversity\",\n",
    "    # \"Action Diversity\",\n",
    "    # \"Success Similarity\",\n",
    "    # \"Demo-SCORE\",\n",
    "    \"CUPID\",\n",
    "    \"CUPID-Quality\",\n",
    "]\n",
    "filter_ratios = [0.00, 0.00, 0.00, 0.00, 0.00]\n",
    "select_ratios = [0.10, 0.25, 0.50, 0.75, 0.90]\n",
    "\n",
    "results = compile_last_n_across_tasks_seeds(\n",
    "    tasks=tasks,\n",
    "    seeds=seeds,\n",
    "    policy=policy,\n",
    "    curate_dataset=True,\n",
    "    exp_curation_keys=plot_curation_keys,\n",
    "    exp_curation_labels=plot_curation_labels,\n",
    "    filter_ratios=filter_ratios,\n",
    "    select_ratios=select_ratios,\n",
    "    curation_train_date=curation_train_date,\n",
    "    reference_train_dates=reference_train_dates,\n",
    ")\n",
    "render_curation_retraining_plot(\n",
    "    results=results,\n",
    "    tasks=tasks,\n",
    "    curation_ratios=select_ratios,\n",
    "    xlabel=\"Fraction of Holdout Demos Selected\",\n",
    "    label_order=plot_curation_labels,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
